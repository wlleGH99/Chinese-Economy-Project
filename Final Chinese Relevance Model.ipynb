{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKOTlwcmxmej"
   },
   "source": [
    "#From: BERT Fine-Tuning Tutorial with PyTorch\n",
    "By Chris McCormick and Nick Ryan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPgpITmdwvX0"
   },
   "source": [
    "*Revised on March 20, 2020 - Switched to `tokenizer.encode_plus` and added validation loss. See [Revision History](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=IKzLS9ohzGVu) at the end for details.*\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX_ZDhicpHkV"
   },
   "source": [
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nSU7yERLP_66"
   },
   "source": [
    "## 1.1. Using Colab GPU for Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GI0iOY8zvZzL"
   },
   "source": [
    "\n",
    "Google Colab offers free GPUs and TPUs! Since we'll be training a large neural network it's best to take advantage of this (in this case we'll attach a GPU), otherwise training will take a very long time.\n",
    "\n",
    "A GPU can be added by going to the menu and selecting:\n",
    "\n",
    "`Edit 🡒 Notebook Settings 🡒 Hardware accelerator 🡒 (GPU)`\n",
    "\n",
    "Then run the following cell to confirm that the GPU is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DEfSbAA4QHas",
    "outputId": "b9c693a8-e261-4912-eb4b-c36463afac52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Get the GPU device name.\n",
    "device_name = tf.test.gpu_device_name()\n",
    "\n",
    "# The device name should look like the following:\n",
    "if device_name == '/device:GPU:0':\n",
    "    print('Found GPU at: {}'.format(device_name))\n",
    "else:\n",
    "    raise SystemError('GPU device not found')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cqG7FzRVFEIv"
   },
   "source": [
    "In order for torch to use the GPU, we need to identify and specify the GPU as the device. Later, in our training loop, we will load data onto the device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oYsV4H8fCpZ-",
    "outputId": "85532145-3ce7-4a1c-ec80-4eef23132b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: Tesla V100-PCIE-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# If there's a GPU available...\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    # Tell PyTorch to use the GPU.    \n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ElsnSNUridI"
   },
   "source": [
    "## 1.2. Installing the Hugging Face Library\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G_N2UDLevYWn"
   },
   "source": [
    "\n",
    "Next, let's install the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT. (This library contains interfaces for other pretrained language models like OpenAI's GPT and GPT-2.) We've selected the pytorch interface because it strikes a nice balance between the high-level APIs (which are easy to use but don't provide insight into how things work) and tensorflow code (which contains lots of details but often sidetracks us into lessons about tensorflow, when the purpose here is BERT!).\n",
    "\n",
    "At the moment, the Hugging Face library seems to be the most widely accepted and powerful pytorch interface for working with BERT. In addition to supporting a variety of different pre-trained transformer models, the library also includes pre-built modifications of these models suited to your specific task. For example, in this tutorial we will use `BertForSequenceClassification`.\n",
    "\n",
    "The library also includes task-specific classes for token classification, question answering, next sentence prediciton, etc. Using these pre-built classes simplifies the process of modifying BERT for your purposes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0NmMdkZO8R6q",
    "outputId": "b5fc96ee-5efd-4f90-f050-e1e05480b567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /share/pkg.7/transformers/4.5.0/install/lib/python3.8/site-packages (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from transformers) (1.18.5)\n",
      "Requirement already satisfied: sacremoses in /share/pkg.7/transformers/4.5.0/install/lib/python3.8/site-packages (from transformers) (0.0.44)\n",
      "Requirement already satisfied: tqdm>=4.27 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (4.51.0)\n",
      "Requirement already satisfied: packaging in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /share/pkg.7/transformers/4.5.0/install/lib/python3.8/site-packages (from transformers) (0.10.2)\n",
      "Requirement already satisfied: filelock in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from transformers) (2.25.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from transformers) (2020.10.28)\n",
      "Requirement already satisfied: click in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from sacremoses->transformers) (0.17.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from requests->transformers) (2020.11.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /share/pkg.7/python3/3.8.6/install/lib/python3.8/site-packages (from requests->transformers) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /share/pkg.7/tensorflow/2.3.1/install/lib/python3.8/site-packages (from requests->transformers) (3.0.4)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lxddqmruamSj"
   },
   "source": [
    "The code in this notebook is actually a simplified version of the [run_glue.py](https://github.com/huggingface/transformers/blob/master/examples/run_glue.py) example script from huggingface.\n",
    "\n",
    "`run_glue.py` is a helpful utility which allows you to pick which GLUE benchmark task you want to run on, and which pre-trained model you want to use (you can see the list of possible models [here](https://github.com/huggingface/transformers/blob/e6cff60b4cbc1158fbd6e4a1c3afda8dc224f566/examples/run_glue.py#L69)). It also supports using either the CPU, a single GPU, or multiple GPUs. It even supports using 16-bit precision if you want further speed up.\n",
    "\n",
    "Unfortunately, all of this configurability comes at the cost of *readability*. In this Notebook, we've simplified the code greatly and added plenty of comments to make it clear what's going on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "guw6ZNtaswKc"
   },
   "source": [
    "# 2. Loading CoLA Dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_9ZKxKc04Btk"
   },
   "source": [
    "We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset for single sentence classification. It's a set of sentences labeled as grammatically correct or incorrect. It was first published in May of 2018, and is one of the tests included in the \"GLUE Benchmark\" on which models like BERT are competing.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JrUHXms16cn"
   },
   "source": [
    "## 2.1. Download & Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7dUNHgCPoPkc",
    "outputId": "fdcc21f1-e49b-4267-dce8-de11cf4c8a91"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Article No</th>\n",
       "      <th>Sample_No</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Article Sentiment</th>\n",
       "      <th>Headline Sentiment</th>\n",
       "      <th>First para. number</th>\n",
       "      <th>First para. Sentiment</th>\n",
       "      <th>Last para.no</th>\n",
       "      <th>Last para. sentiment</th>\n",
       "      <th>Id</th>\n",
       "      <th>UniqueId</th>\n",
       "      <th>Headline</th>\n",
       "      <th>First Paragraph</th>\n",
       "      <th>Last Paragraph</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>XINCCN0020021028dyas000xe</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社十月二十八日发稿目录（三）</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>XINCCN0020021027dyar000b9</td>\n",
       "      <td>2</td>\n",
       "      <td>俄未能批准《京都议定书》 气候变化大会前景暗淡</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>XINCCN0020021209dyc90019j</td>\n",
       "      <td>3</td>\n",
       "      <td>中国明年将对房地产市场等进行专项整治</td>\n",
       "      <td>从１９９８年开始，中国先后开展了打击走私、骗汇、骗取出口退税和制售假伪劣商品等违法犯罪活动的...</td>\n",
       "      <td>整治集贸市场、加油站和旅游市场打假打非等今年以来部署的专项斗争，要抓住重点进一步加大力度，争...</td>\n",
       "      <td>中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>XINCCN0020021126dybq000sr</td>\n",
       "      <td>4</td>\n",
       "      <td>上海正在打破世界级城市的交通瓶颈</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002</td>\n",
       "      <td>44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "      <td>XINCCN0020020902dy8u00002</td>\n",
       "      <td>5</td>\n",
       "      <td>中国启动一项特困大学生资助项目</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Article No  Sample_No  Relevance  Article Sentiment  \\\n",
       "0  2002         10        NaN          1                  0   \n",
       "1  2002         22        NaN          1                  0   \n",
       "2  2002         36        NaN          0                  3   \n",
       "3  2002         40        NaN          1                  0   \n",
       "4  2002         44        NaN          1                  0   \n",
       "\n",
       "   Headline Sentiment  First para. number  First para. Sentiment  \\\n",
       "0                  99                  99                     99   \n",
       "1                  99                  99                     99   \n",
       "2                   3                   1                      3   \n",
       "3                  99                  99                     99   \n",
       "4                  99                  99                     99   \n",
       "\n",
       "   Last para.no  Last para. sentiment                         Id  UniqueId  \\\n",
       "0            99                    99  XINCCN0020021028dyas000xe         1   \n",
       "1            99                    99  XINCCN0020021027dyar000b9         2   \n",
       "2             5                     4  XINCCN0020021209dyc90019j         3   \n",
       "3            99                    99  XINCCN0020021126dybq000sr         4   \n",
       "4            99                    99  XINCCN0020020902dy8u00002         5   \n",
       "\n",
       "                  Headline                                    First Paragraph  \\\n",
       "0         新华社十月二十八日发稿目录（三）                                                NaN   \n",
       "1  俄未能批准《京都议定书》 气候变化大会前景暗淡                                                NaN   \n",
       "2       中国明年将对房地产市场等进行专项整治  从１９９８年开始，中国先后开展了打击走私、骗汇、骗取出口退税和制售假伪劣商品等违法犯罪活动的...   \n",
       "3         上海正在打破世界级城市的交通瓶颈                                                NaN   \n",
       "4          中国启动一项特困大学生资助项目                                                NaN   \n",
       "\n",
       "                                      Last Paragraph  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2  整治集贸市场、加油站和旅游市场打假打非等今年以来部署的专项斗争，要抓住重点进一步加大力度，争...   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                             Content  \n",
       "0  新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...  \n",
       "1  俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...  \n",
       "2  中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...  \n",
       "3  上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...  \n",
       "4  中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_df=pd.read_excel('Chinese Complete Dataset.xlsx') #Use file path\n",
    "raw_df = raw_df[raw_df.Relevance<= 2]\n",
    "raw_df['Relevance'] -= 1\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oeJzve_afxU-",
    "outputId": "40ec3a6d-6ff6-4c9e-b2ef-d6afc19e5f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7608"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(raw_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "sgyZOqc1hqo1",
    "outputId": "d0564980-c4f3-46fc-c782-7df83d10e472"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueId</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueId  Relevance                                            Content\n",
       "0         1          1  新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...\n",
       "1         2          1  俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...\n",
       "2         3          0  中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...\n",
       "3         4          1  上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...\n",
       "4         5          1  中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['UniqueId'] = raw_df['UniqueId']\n",
    "df['Relevance'] = raw_df['Relevance']\n",
    "df['Content'] = raw_df['Content']\n",
    "df = df.dropna()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "U4SVXhOqb3dA",
    "outputId": "aef93527-1fbc-418a-b2f6-88ac622102a3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueId</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5873</td>\n",
       "      <td>5873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1735</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UniqueId  Content\n",
       "Relevance                   \n",
       "0              5873     5873\n",
       "1              1735     1735"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Relevance'] = df['Relevance']*-1 + 1 # Make 0 as irrelevant and 1 as relevant\n",
    "df.groupby('Relevance').count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "eqVTt1PeBfv1",
    "outputId": "1445c75b-7b5b-4218-8cc7-73dc2259f353"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueId</th>\n",
       "      <th>Relevance</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   UniqueId  Relevance                                            Content\n",
       "0         1          0  新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２...\n",
       "1         2          0  俄未能批准《京都议定书》 气候变化大会前景暗淡\\n本月早些时候，俄罗斯曾表示可能在今年１１月...\n",
       "2         3          1  中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取...\n",
       "3         4          0  上海正在打破世界级城市的交通瓶颈\\n上海地处中国大陆海岸线的中点，目前拥有常住人口１６４０万...\n",
       "4         5          0  中国启动一项特困大学生资助项目\\n中年妇女童陵陵是八一电影制片厂的职工，女孩杨文敬来自北京市..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "0YmWzGy6fzVg"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UniqueId</th>\n",
       "      <th>Content</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Relevance</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1773</td>\n",
       "      <td>1773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1735</td>\n",
       "      <td>1735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           UniqueId  Content\n",
       "Relevance                   \n",
       "0              1773     1773\n",
       "1              1735     1735"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "remove_n = 4100\n",
    "\n",
    "new_drop_indices = np.random.choice(df[df['Relevance'] == 0].index, remove_n, replace=False)\n",
    "\n",
    "df = df.drop(new_drop_indices)\n",
    "\n",
    "df.groupby('Relevance').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "y6lTSTzrtgC5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "allsentences=df['Content'].values\n",
    "alllabels = df['Relevance'].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "sentences, test_sentences, labels, test_labels = train_test_split(allsentences, alllabels, test_size=0.1, random_state=10, shuffle=True, stratify=alllabels)\n",
    "sentences = np.concatenate([sentences, test_sentences])\n",
    "labels = np.concatenate([labels, test_labels])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TAjjfMC6i591",
    "outputId": "744e93b3-48ca-4629-b9e1-23abb228222a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3508"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "su7CSqpgkdsq",
    "outputId": "638b763c-b884-4bd0-a3d1-1fc64e77b5b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['新华社十月二十八日发稿目录（三）\\n新疆北鲵种群数量迅速恢复徐匡迪认为，中国实现工业化还须２０年时间今日北京主要报纸要闻标题摘选中国无公害农作物种植面积大幅增长“天然中药库”陕西商洛建中药材博物馆亚洲证券界人士看好中国资本市场香港供水服务在亚洲城市中最佳东北虎林园决定：咬人东北虎留在虎园参与繁殖港澳台津四地歌手在高雄同台献艺浙江与日本静冈县庆祝结成友好省县关系２０周年大型水利工程廖坊水利枢纽工程开工今日沪深股市行情冯晓增说，保险业成为中国社会巨变的缩影台湾半数受访民众患“双率焦虑症”一批中国艺术精品在港高价成交尉健行出席《工会法》修改颁布实施一周年座谈会香港举办亚太区资讯科技及电讯统计会议联合国大学在澳门为发展中国家积极培训人才澳门报纸指出，两岸“三通”是台湾的最大民意今年中国经济增长速度将高於７％澳门莲花卫视开播大型理论文献电视片《走进新时代》即将播出（中国成就）与时俱进闯新路江泽民会见俄罗斯总理卡西亚诺夫国际新闻委内瑞拉总统抨击反政府势力国际调解人推动委内瑞拉内部和解亚太经合组织第十次领导人非正式会议发表《领导人宣言》加总理重申俄解救人质行动是不得已的决定天文学家新发现天王星第２１颗卫星亚太经合组织领导人发表反恐声明反恐专家说车臣武装分子可能密谋袭击欧洲江泽民会见韩国总统金大中印尼鹰记航空公司决定配备“空中安全官”江泽民会见日本首相小泉印尼成立专职反恐机构美研究发现一种合成物质可防治骨质疏松菲律宾８名渔民遭海盗杀害澳两艘护卫舰开往海湾监控伊拉克海上运输印度发生炸弹爆炸至少１３人丧生俄官员说多数人质的死亡是“特殊气体”造成的韩国向朝鲜移交４具朝鲜居民尸体悉尼发生４０多起攻击穆斯林的案件越南一工厂发生百名工人中毒事件美国驻约旦使馆一工作人员被枪杀粗俗喜剧片《蠢人搞笑》夺得北美票房冠军题：共商大计再聚首加蓬重申要努力维护中非地区的和平与稳定新闻分析：卢拉当选巴西总统的原因及面临的挑战新华社技术局 ',\n",
       "       '中国明年将对房地产市场等进行专项整治\\n从１９９８年开始，中国先后开展了打击走私、骗汇、骗取出口退税和制售假伪劣商品等违法犯罪活动的专项斗争，取得明显成效﹔去年４月以来，国务院又先后统一部署了联合打假、整顿文化市场、严厉打击传销、整顿建筑市场、强化税收征管、集贸市场专项整治、加油站专项整治、旅游市场打假打非等８个专项斗争，严厉打击了破坏市场经济秩序的违法犯罪活动，依法惩治了一大批违法犯罪分子\\n这位负责人说，下一步的专项整治工作要突出重点，狠抓大案要案的查处，集中力量整治与群众切身利益密切相关、群众关心、关系全局的问题\\n除组织新的专项斗争外，联合打假要长抓不懈，继续集中力量加大对非法生产经营的打击力度﹔整顿和规范建筑市场、强化税收征管和金融信用秩序、打破地方保护与行业垄断、整顿文化市场、安全生产管理和安全监察、严厉打击传销及变相传销活动等专项斗争\\n这位负责人表示，要继续保持高压态势，边整边改、建章立制，从完善法规和执法机制等方面弥补漏洞\\n整治集贸市场、加油站和旅游市场打假打非等今年以来部署的专项斗争，要抓住重点进一步加大力度，争取在明年一季度取得明显的阶段性成效\\n（完） ',\n",
       "       '中国美容从业人员达２０００万\\n这２０００万从业者遍布于中国各地的１５４．２万家美容机构，平均每个就业者的年收入为２．４万人民币\\n北京大学经济学院特聘教授李玲瑶博士说，美容业是吸纳新生劳动力和失业人员再就业的新途径\\n中国将会有越来越多的人特别是女性从中找到就业机会\\n针对这么多的美容从业者，北京、上海等地已经建立美容业公会，以加强对从业人员管理和指导\\n此外，美容师必须经过考核后，合格后持统一证件才能上岗\\n据中国国家统计局资料显示，中国美容业在国内生产总值中所占的比重呈增长态势\\n预计未来５年，中国美容业的营业额还将再翻一番，美容业的就业人员也会大幅增长\\n这份调查中还提到，中国美容就业人员接受教育的程度略显偏低，人均就业时间很短，仅为４．８年\\n（完） ',\n",
       "       ...,\n",
       "       '今年北京GDP预计增长6%左右\\n政府工作报告指出,今年一般公共预算收入规模与上年持平；去年PM2.5年均浓度降至42微克/立方米\\n\\n新京报讯 （记者李玉坤） 1月12日上午，北京市第十五届人民代表大会第三次会议在北京会议中心开幕，市长陈吉宁代表市人民政府向大会作政府工作报告\\n报告全面系统回顾了2019年工作，明确了2020年需要重点做好的任务\\n报告指出，2019年，北京地区生产总值预计增长6.2%左右\\n2020年，北京地区生产总值增长安排6%左右\\n\\n新增一项指标 体现首都减量发展特征\\n报告提出，在保持指标体系稳定性、连续性的基础上，按照高质量发展要求，对指标体系进行适当调整，新增“单位地区生产总值建设用地使用面积降幅”指标，该指标能体现首都减量发展特征，有利于引导全市更加重视地均产出，促进土地集约节约利用\\n调整后的计划指标数量由30项增加至31项\\n\\n2019年，北京经济增速处于合理区间，预计GDP全年增长6.2%左右\\n2020年，综合考虑经济运行态势和实现就业、居民收入等重要目标的需要，北京地区生产总值增长安排6%左右\\n全员劳动生产率超过26.5万元/人，保持全国领先\\n\\n新出现的指标——单位地区生产总值建设用地使用面积预计下降4.36%\\n另外，单位地区生产总值能耗、二氧化碳排放分别较2015年下降17%和20.5%，单位地区生产总值水耗下降3%左右\\n\\n今年全面完成“疏整促”阶段性工作任务\\n报告提出，2020年，北京将全面完成“疏整促”阶段性工作任务\\n主要任务有，有序退出一般制造业企业90家，疏解提升区域性专业市场和物流中心66个，对涉及重要民生保障需要保留的市场进行升级改造，持续推进教育医疗等公共服务资源布局优化\\n此外，要把疏解工作向核心区公交场站、旅游集散中心延伸\\n\\n未来一年，北京将以治理类街乡镇为重点，坚持计划管理与动态清零、主动治理与“接诉即办”紧密结合，拆除违法建设腾退土地4000公顷以上\\n\\n在老旧小区综合整治提升方面，北京将坚持清单式自下而上申报制模式，实现新开工80个项目，加装电梯开工400部以上、完工200部以上\\n\\n一图读懂北京市政府工作报告\\n2019年工作成绩\\n●全市地区生产总值比上年增长6.2%左右\\n●一般公共预算收入增长0.5%\\n●居民消费价格上涨2.3%\\n●城镇调查失业率保持在4.4%左右\\n●全市居民人均可支配收入实际增长6.3%左右\\n●单位地区生产总值能耗、水耗分别下降4%和3%左右\\n●细颗粒物年均浓度降至42微克/立方米\\n重大活动服务保障\\n●全面出色完成新中国成立70周年庆祝活动服务保障任务\\n●成功举办2019年中国北京世界园艺博览会\\n疏解整治促提升\\n●退出一般制造业企业399家，疏解提升市场和物流中心66个，拆除违法建设腾退土地5706公顷\\n●“留白增绿”完成绿化1686公顷\\n交通\\n●全市支路以上路侧停车实现电子收费\\n●7号线东延、八通线南延建成通车\\n●北京大兴国际机场建成通航\\n●京张高铁开通运营\\n人才引进\\n●引进人才落户3500余人\\n●积分落户实现全网通办，6007人取得落户资格\\n优化营商环境\\n●群众办事申请材料和办理时限均压减60%\\n●895项事项全程网办，150项事项自助办\\n●减税降费为企业和社会减负约1800亿元\\n企业发展\\n●12家北京企业成功挂牌科创板\\n●全市拥有独角兽企业82家，居全国首位\\n民生\\n●新建街道乡镇养老照料中心20家和社区养老服务驿站160家\\n●建设筹集政策性租赁住房5.02万套，新开工政策性产权住房6.68万套，完成棚户区改造1.63万户\\n●新增学前教育学位3万余个\\n2020年重点工作\\n创新驱动发展\\n●实施促进科技成果转化条例\\n●出台我市构建现代化经济体系实施方案\\n●实施制造业数字化、智能化、绿色化改造提升计划\\n●重点发展集成电路产业\\n京津冀协同发展\\n●更有力推动城市副中心高质量发展\\n●精心筹办北京冬奥会、冬残奥会，所有竞赛场馆全部完工，加快冬奧村等非竞赛场馆建设\\n\\n优化营商环境\\n●落实优化营商环境3.0版改革政策\\n●支持“外摆”“快闪”等新型消费形式发展\\n●再推出一批“一件事套餐服务”\\n●统一全市各级服务事项标准\\n城市治理\\n●绿色出行比例提高到75%\\n●开展重要道路100处交通信号灯配时优化\\n●优化调整80条公交线路\\n●实施20项市级疏堵工程\\n●新增造林绿化17万亩\\n●完成200公里污水管线建设\\n●实施新修订的生活垃圾管理条例\\n城乡统筹发展\\n●完成美丽乡村建设三年行动计划\\n●开展第三批村庄规划编制\\n●农村无害化卫生厕所覆盖率达到98%以上\\n●深入实施新一轮城市南部地区发展行动计划，有效提升大兴、房山等南部新城综合承载力\\n民生\\n●试点推进健康联合体和紧密型医联体建设，实现每万名居民拥有3名全科医生\\n●大力推进老旧小区综合整治，实现新开工80个项目\\n疏解整治促提升\\n●全面完成疏解整治促提升专项行动阶段性任务\\n●拆除违法建设腾退土地4000公顷以上\\n●制定实施背街小巷环境精细化治理三年行动计划\\n●腾退土地实现增绿1600公顷\\n●建设提升1000个便民商业网点\\n●完成“回天地区”三年行动计划任务\\n2020年主要预期目标\\n●地区生产总值增长6%左右\\n●一般公共预算收入规模与上年持平\\n●居民消费价格涨幅控制在3.5%以内\\n●城镇调查失业率低于5%\\n●居民收入增长与经济增长基本同步\\n●单位地区生产总值能耗较2015年下降17%\\n●单位地区生产总值二氧化碳排放较2015年下降20.5%\\n●单位地区生产总值水耗下降3%左右\\n解读1\\n如何看待2019年北京GDP增速？\\n首都经济运行总体平稳，稳中有进\\n政府工作报告提到，初步预计，全市地区生产总值比上年增长6.2%左右\\n\\n北京市发改委相关负责人解释，2019年，面对稳中有变的发展形势，北京始终坚持稳中求进工作总基调，以稳应变，以进固稳，在这个过程中首都经济运行总体平稳，稳中有进\\n\\n“稳”体现在两个方面，首先是主要指标处于合理区间，预计全年GDP增长6.2%左右，符合年初6%～6.5%的预期目标\\n另外，优势服务业支撑平稳，占全市经济比重达83.1%的服务业增长稳定，提升了首都经济抗风险能力，金融、信息、科技三大优势产业增加值对经济增长的贡献率保持在65%以上\\n\\n“进”也体现在两个方面，发展质量效益提高，人均GDP约2.4万美元，全员劳动生产率超过26万元/人，保持全国领先，单位地区生产总值能耗和水耗分别下降4%左右和3%左右\\n此外，高质量发展动力源在加快打造，“三城一区”统筹建设水平全面提升，互融共进的科技创新格局加快构建\\n北京大兴国际机场建成通航，首都进入航空“双枢纽”发展时代；以新一代信息技术与医药健康为引领，高精尖产业发展新动能加快塑造\\n\\n解读2\\n今年GDP增速目标为何定为6%左右？\\n综合考虑经济运行态势和实现就业等目标需要\\n政府工作报告提到，2020年地区生产总值安排增长6%左右\\n市发改委相关负责人介绍，确定2020年经济增长6%左右的预期目标，主要考虑几个因素\\n\\n从目标衔接看，按照2019年GDP增长6.2%考虑，2020年GDP增速达到5.9%左右，可实现“十三五”规划“GDP年均增速达到6.5%”目标\\n\\n从国际形势看，外部环境复杂严峻，国际货币基金组织（IMF）2019年10月份将2020年全球贸易额增速和全球经济增速分别下调至3.2%和3.4%，较7月分别下调了0.5和0.1个百分点\\n从国内看，我国经济稳中向好、长期向好的基本趋势没有变，但既有的结构性体制性矛盾和经济转型升级阵痛相互交织，经济下行压力加大，世界银行、国际货币基金组织（IMF）、经济合作与发展组织（OECD）等机构分别预测2020年我国经济增速为6.1%、6%、5.7%\\n\\n从产业看，近年来占比超过80%的服务业增速比较稳定，2011年以来增速比GDP平均高0.5个百分点左右，预计2020年仍将保持较快增长，特别是占全市GDP比重超四成、对经济增长贡献率合计近七成的金融、信息、科技等重点行业仍将保持较快增长\\n从实际支撑看，本市经济布局加速优化，创新优势持续增强，产业发展更加聚焦，质量效益稳步提升，营商环境改革全面深化，都为经济发展打下了良好基础，增添了新的动力和活力\\n综合考虑经济运行态势和实现就业、居民收入等重要目标的需要，2020年的GDP增速安排在6%左右\\n\\n解读3\\n今年财政收支预算为何与上年持平？\\n综合考虑经济发展、物价及减税降费影响\\n昨日，北京市十五届人大三次会议开幕，北京市2019年预算执行情况和2020年预算（草案）的报告提交大会审议\\n根据报告，今年全市一般公共预算收支预算拟按与2019年持平安排\\n具体来看，全市一般公共预算收入预期5817.1亿元，收入规模与上年持平；全市一般公共预算支出7031亿元，支出规模与上年持平\\n全市一般公共预算收支平衡\\n\\n过去，当年财政收支预算都会较上年有所增加，比如，2017年安排全市一般公共预算收入预期5411.6亿元，增长6.5%；2018年安排5783.8亿元，增长6.5%左右；2019年由于落实减税政策等原因，在年中调整预算目标，但年初制定的目标为6015.0亿元，增长4.0%\\n\\n今年的财政预算收支为何与上年持平？对此，北京市财政局副局长、新闻发言人韩杰表示，2020年，北京市规模以上企业工业利润下降、传统商业换挡升级等因素，使经济下行的压力仍在加大，导致财政收入运行存在一定不确定性\\n\\n同时，2019年已出台的减税降费政策，在2020年还会有一定的政策影响期，政策翘尾减收约240亿元；再加上2019年组织国企上缴利润和清理历史欠税等一次性增收因素形成收入的高基数，这些都对2020年收入运行形成压力\\n\\n本着积极稳妥的原则，2020年全市一般公共预算收入增长拟按与上年保持持平安排\\n\\n尽管财政收支矛盾突出，但韩杰强调，整体来看，2020年北京市经济稳中向好，营商环境持续改善，重点行业发展向好，这些都是有利于财政收入增长的因素\\n\\n韩杰表示，从数据上看是与2019年持平，但实际并非没有增长，若将减税降费政策和一次性增收因素还原，2020年全市财政收入同口径增幅约7.3%，基本与GDP及物价变动情况相匹配\\n 新京报记者 李玉坤 姜慧梓\\n亮点\\n一枚印章管审批……优化营商环境新提法最多\\n“一枚印章管审批”“研究型病房”“‘类海外’环境”“老城双修”“点亮北京”“慢行网络”……今年的政府工作报告中出现诸多“新提法”，揭示了新一年工作的创新思路\\n从这些“新提法”中可以看出北京“微观改革”的信号\\n新京报记者发现，在优化营商环境方面，报告出现的“新提法”最多\\n\\n优化营商环境“新提法”最多\\n政府工作报告每年都会出现一些“新提法”“新概念”\\n这些“词汇”揭示着政府一年工作的创新思路\\n\\n今年的政府工作报告中就出现了不少新提法\\n比如，完善国际教育、国际医疗等配套政策和设施，加快国际人才社区建设，持续营造“类海外”环境；在城市副中心建设“智能政务服务大厅”……\\n记者发现，这些新提法有的高度概括，有的形象直观，体现了北京在城市治理、科技创新中心建设、优化营商环境等方面的新思路、新举措、新方法\\n\\n在“深化改革开放，打造国际一流的营商环境高地”方面，报告中的新提法最为密集\\n除“‘类海外’环境”外，还包括“一枚印章管审批”“一件事套餐服务”“秒批”“智能政务服务大厅”“点亮北京”“过境过夜游”等\\n\\n据了解，北京去年已先后实施优化营商环境2.0版、3.0版改革政策，在国内营商环境评价中继续保持第一，为我国营商环境世行排名进一步提升作出突出贡献\\n\\n“微观视角”改进办事体验\\n记者注意到，在今年政府工作报告新提法中，不乏“微观视角”的改革，简化企业、市民的办事流程，优化体验\\n\\n比如，北京将加快构建以信用为基础的新型监管机制，推行告知承诺审批制度改革，将在北京经济技术开发区试行“一枚印章管审批”；聚焦企业、群众办事创业全过程中难点、痛点，以“办成一件事”为目标的“一件事套餐服务”等\\n\\n今年，北京还将彻底清理各级政府部门的“僵尸电话”；并探索实行基层行政服务大厅周末服务制度，基层办事有望逐步实现“周末不打烊”\\n\\n此外，北京还将通过 “‘热线+网络’为民服务模式”，让“接诉即办”“未诉先办”通过更多渠道服务更多市民\\n“重点区域定制公交服务”也体现了因时因地制宜服务市民的思路\\n 新京报记者 沙雪良',\n",
       "       '吉祥航空推“畅飞卡”：不限次飞到明年 10点开售后App“挤爆”了\\n\\n东方网记者王佳妮8月18日报道：继7月初推出“无限升舱卡”后，吉祥航空今日再次推出两款全新客票产品：“吉祥畅飞卡”与“儿童畅飞卡”\\n东方网记者从吉祥航空获悉，旅客只需支付2888元与61元，便可在有效期内无限次、不限日期兑换吉祥航空国内航班经济舱客票，进一步惠及高频次商务旅行及家庭旅行\\n\\n\\nhttps://mz.eastday.com/18903228.jpg?imageslim\\n东方网记者注意到，“吉祥畅飞卡”与“儿童畅飞卡”今天10点正式开售后，由于App在线人数激增而导致访问缓慢\\n对此，吉祥航空官方微博发布了相关提示，表示技术人员正在加紧优化系统，请各位旅客耐心等待\\n\\n\\n据了解，此次吉祥航空推出的“吉祥畅飞卡”与“儿童畅飞卡”是基于中国商旅和度假型旅客出行需求而推出，产品将惠及成人旅客与2至12周岁儿童旅客\\n购买该产品旅客将灵活选择在2021年1月20之前搭乘所有吉祥航空所承运国内航线（暂不包含港澳台地区）\\n吉祥航空承诺确保每个航班至少保留30个坐席以服务购买上述产品的旅客\\n\\n\\nhttps://mz.eastday.com/18903227.jpg?imageslim\\n\\n购买“吉祥畅飞卡”与“儿童畅飞卡”的旅客将享受与普通票价产品同等的会员权益，并包含了免费餐食和托运行李额度在内的其他权益，并可与吉祥航空“升舱券”搭配使用，以获得更好的飞行体验\\n\\n\\n值得注意的是，每名吉祥航空注册成人会员可至多购买10张“吉祥畅飞卡”或“儿童畅飞卡”产品，并需通过吉祥航空APP完成实名制认证绑定自用或转赠亲友绑定后使用\\n乘机人需在航班计划起飞时间5天前完成兑换，且最多同时存在4段使用畅飞卡兑换的未使用航段；同时同一日期同一始发城市仅可存在1段使用畅飞卡兑换的未使用航段；“儿童畅飞卡”旅客需成人陪伴出行\\n\\n事实上，吉祥航空近期”大动作“不断\\n此前，吉祥航空刚公布9月国际航班执行情况\\n东方网记者注意到，9月，吉祥航空在原有4条国际航线（芬兰、日本、新加坡、泰国）基础上新增每周一班南京至大阪直飞航班',\n",
       "       '新时期新就业丨鼓励灵活就业 急需制度创新\\n\\n“要取消对灵活就业的不合理限制，引导劳动者合理有序经营\\n”李克强总理在7月22日的国务院常务会议上强调\\n\\n\\n今年4月份我国城镇调查失业率是6%，5月份为5.9%，6月份为5.7%\\n尽管调查失业率略降，但就业压力仍不容乐观\\n调查失业率略降主要是防疫形势走好，使得经济运行逐步改善和员工复岗情况持续好转，但当前就业总量压力较大\\n据国家统计局统计，目前，就业不充分现象较为明显，就业人员处于在职未就业状态，高于往年正常水平；企业就业人员周平均工作时间比上年同期减少\\n同时，大学生等重点群体就业压力仍大，随着高校毕业生集中进入劳动力市场，大学生失业率可能继续上升\\n在这样的背景下，鼓励灵活就业，取消对灵活就业的不合理限制，就显得尤为急切\\n\\n今年上半年，人力资源社会保障部门实施社保助企“免减缓”行动、失业保险援企稳岗行动、百日千万网招行动、百日免费线上技能培训行动等，同时扩大失业保险保障范围，取得了不错的成效\\n近期，人社部又发布第二季度全国招聘求职100个短缺职业排行，7月21日，国家级招聘求职服务平台“就业在线”正式上线\\n这些政策都为灵活就业创造了各种条件，但让灵活就业灵而不拙，活而不僵，还需要各地各部门通过探索制度创新来推动\\n就像总理所说，“就业不可能全靠政府通过‘计划’来完成，而是要尽力发挥人民群众无穷的创造力去实现\\n这也是中国经济韧性的重要表现\\n”而保护劳动者就业的创造力，则需要政府制度的创新力支撑\\n\\n\\n比如保险方面\\n按照法律规定，如果灵活就业人员没有劳动合同关系，用工企业并没有法定的社会保险缴纳义务，虽说灵活就业人员个人可以按照国家规定，以灵活就业身份缴纳医疗保险、养老保险，虽说女性灵活就业者只要缴纳了医疗保险也可以享受到生育保险的待遇，但不管男女，失业保险和工伤保险都是没有的\\n而灵活就业的不确定性，失业保险和工伤保险又显得特别重要，因为灵活就业必须是兼职越多，对个人的保障才越大\\n像一个外卖小哥，可能同时为不同的平台服务，工伤了算谁的？没有哪个平台说“算我的”\\n即使本人想个人缴纳，也没有缴纳途径\\n\\n\\n对此，政府部门不妨通过制度设计做一些创新，没有劳动关系也可以自己缴纳工伤保险\\n对于同时为多家公司服务的，有关部门可指定一家为劳动者开设账户\\n\\n\\n再比如职业培训\\n政府部门对所辖区域内有多少人没工作、以前干过什么职业等情况不掌握，虽然组织了免费培训，但又不与工作岗位直接挂钩，劳动者对此没有积极性\\n虽说企业用人可以自行培训，但企业不会广而告之，宣传成本小越好\\n这只能靠劳动者自己四处瞎碰，往往事倍功半\\n\\n\\n对此，各地政府部门要建立就业信息平台，与社区和企业建立信息链接，把供需双方精准对接起来，政府组织的培训或购买的培训也能有的放矢\\n同时可探索建立个人职业培训账户制度，随时掌握劳动者失业就业情况，便于政府及时调整政策\\n\\n\\n总之，对于灵活就业，已经有明确制度设计的，就要加紧落实\\n还没有制度设计的，就要加快创新\\n对相互竞争的城市来说，这也是竞争力，而且是更深入人心的竞争力'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['Headline'].values\n",
    "df['Content'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ex5O1eV-Pfct"
   },
   "source": [
    "# 3. Tokenization & Input Formatting\n",
    "\n",
    "In this section, we'll transform our dataset into the format that BERT can be trained on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8kEDRvShcU5"
   },
   "source": [
    "## 3.1. BERT Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWOPOyWghJp2"
   },
   "source": [
    "\n",
    "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
    "\n",
    "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxdxv8lToT8z",
    "outputId": "623bec7e-7b89-4dfe-e7c1-6190a9f5701f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /usr4/ugrad/wlew/.local/lib/python3.8/site-packages (0.1.96)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.4; however, version 21.2.4 is available.\n",
      "You should consider upgrading via the '/share/pkg.7/python3/3.8.6/install/bin/python3.8 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z474sSC6oe7A",
    "outputId": "13a613fc-c510-4cf7-f103-e7c3dc03b3f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading BERT tokenizer...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='xlm-roberta-base', vocab_size=250002, model_max_len=512, is_fast=True, padding_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=False)})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "print('Loading BERT tokenizer...')\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dFzmtleW6KmJ"
   },
   "source": [
    "Let's apply the tokenizer to one sentence just to see the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dLIbudgfh6F0",
    "outputId": "38d1b84c-8d56-4b74-e037-5264cb597639"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1105 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original:  （世说中国策）中拉经贸合作跃级而升之三——金融助益转型升级\n",
      "新华社北京５月２１日电中拉经贸合作跃级而升之三——金融助益转型升级\n",
      "新华社记者刘云非当地时间２０日，巴西裏约地铁迎来一位特殊乘客——正在巴西访问的中国国务院总理李克强\n",
      "李克强总理坐在裏约地铁“中国造”车厢内具有象徵意义：从贸易、产业到投融资，中拉经贸合作渐次推进，正呈现出新图景\n",
      "\n",
      "海外观察家指出，大型项目和钜额投资，让李克强拉美行在首站巴西就掀起“中国旋风”；而中国深耕拉美的大背景是，步入经济新常态的中国与致力于转型的拉美正调整好步调深化合作，新的契合点则提供了新动力\n",
      "\n",
      "访问中，李克强提出中拉产能合作新模式：契合拉美国家需求，共同建设物流、电力、信息三大通道，实现南美大陆互联互通；遵循市场经济规律，实现企业、社会、政府三者良性互动的合作方式；围绕中拉合作项目，拓展基金、信贷、保险三条融资渠道\n",
      "中方将设立中拉产能合作专项基金，提供３００亿美元融资，支持中拉在产能和装备制造领域的项目合作\n",
      "此外，中国愿同拉美国家扩大货币互换及本币结算\n",
      "\n",
      "对拉美而言，过去１０年大宗商品驱动的高速增长带来消费市场繁荣，但也掩盖了结构性问题\n",
      "教育、固定资产、基础设施投入滞后，令经济增长内生动力不足\n",
      "数据显示，过去几年拉美地区投资率仅约２０％，远低于世界平均水准\n",
      "重消费、轻投资的增长模式，制约了拉美经济可持续增长\n",
      "\n",
      "“越来越多的声音认为，在中拉日益增长的贸易中，应当减少对中国购买拉美原材料的关注，转而更多地推动中国从拉美进口加工产品和在拉美增加投资，”埃菲社如此点评中拉经贸合作新趋势\n",
      "\n",
      "分析人士表示，中拉经贸合作正经历转变：由劳动密集型产品转向高端制造产品以及服务和技术输出，从以贸易为主转向以投资、工程承包为主\n",
      "而在ꊮ基础设施、信息通信、新能源等重点合作领域，金融将扮演“催化剂”和“倍增器”的角色\n",
      "\n",
      "中巴工商峰会期间，交通银行就收购巴西ＢＢＭ银行与其控股股东签署协议\n",
      "交行董事长牛锡明表示，交行将为ＢＢＭ银行注入中国元素，更好服务两国投资与贸易活动，为“走出去”的中企和巴西本地客户提供更优质的金融服务\n",
      "\n",
      "国家开发银行与巴西石油公司签署中长期融资合作协议，并与巴西一州政府及国内一家企业就玉米和大豆深加工项目签署合作框架协议，共涉及融资金额约６０亿美元\n",
      "此外，中国进出口银行分别与巴西多家机构签署总值６６．５亿美元协议，涉及高端船型、海洋工程装备、航空器等领域\n",
      "\n",
      "中国出口信用保险公司与巴西征信机构ＳＥＲＡＳＡ签署战略合作协议，两家机构将在资信信息和保后支持服务方面展开长期合作\n",
      "据悉，中国信保在巴西市场累计保额已达３０８亿美元，以中长期出口信用保险、投资保险等方式支持中企参与巴西冶金、水泥、电信等行业１４个长期项目，未来将继续支持产能、农业和本币互换等领域合作\n",
      "\n",
      "此前，中国央行分别与阿根廷和巴西央行签署双边本币互换协议\n",
      "据悉，智利央行和中国央行有关本币互换的谈判也取得进展\n",
      "通过货币互换，可相互提供短期流动性支持，并为本国商业银行在对方国家分支机构提供该国货币的融资便利，帮助企业规避汇率风险和降低交易成本\n",
      "而本币结算有助于汇率形成机制，贸易和投融资将得到跃升\n",
      "\n",
      "中国资本“走出去”带动中企和高端装备“出海”，拉美成为最具潜力市场之一\n",
      "目前，中国与阿根廷、巴西在动车生产领域深度对接\n",
      "截至２０１４年年底，中国累计在拉美和加勒比国家新签工程承包额超过１１００亿美元，涉及天然气、管道、电站、公路、港口、住房、通信和铁路等领域\n",
      "\n",
      "拉美开发银行行长加西亚表示，拉美基础设施相对薄弱、工业化水准较低，而中国在技术、资金和经验方面有优势，双方进行产能合作“恰逢其时”\n",
      "拉美开发银行将积极融入双方金融合作，为中企进军拉美和加速国际融合铺平道路\n",
      "\n",
      "随着巴西成为亚投行在美洲的唯一意向创始成员国，审视中拉金融合作的视野更为宽广\n",
      "“巴西有不少国际项目经验丰富的建筑承包企业，在亚洲也有业务，亚投行的创立客观上有助于拉近巴西与整个亚洲的距离，”巴西驻华大使雷昂说\n",
      "智利总统巴切莱特也表示，亚投行很重要，智利正在评估加入亚投行的可行性\n",
      "\n",
      "从初级产品贸易到发展战略对接，中拉深度融合开辟了广阔的合作前景，也将助推世界经济均衡、可持续增长\n",
      "（完）\n",
      "Tokenized:  ['▁(', '世', '说', '中国', '策', ')', '中', '拉', '经贸', '合作', '跃', '级', '而', '升', '之', '三', '——', '金融', '助', '益', '转型升级', '▁', '新华社', '北京', '5', '月', '21', '日电', '中', '拉', '经贸', '合作', '跃', '级', '而', '升', '之', '三', '——', '金融', '助', '益', '转型升级', '▁', '新华社', '记者', '刘', '云', '非', '当地时间', '20', '日', ',', '巴西', '裏', '约', '地铁', '迎来', '一位', '特殊', '乘客', '——', '正在', '巴西', '访问', '的中国', '国务院', '总理', '李克强', '▁', '李克强', '总理', '坐在', '裏', '约', '地铁', '“', '中国', '造', '”', '车', '厢', '内', '具有', '象徵', '意义', ':', '从', '贸易', '、', '产业', '到', '投', '融资', ',', '中', '拉', '经贸', '合作', '渐', '次', '推进', ',', '正', '呈现', '出', '新', '图', '景', '▁', '海外', '观察', '家', '指出', ',', '大型', '项目', '和', '钜', '额', '投资', ',', '让', '李克强', '拉', '美', '行', '在', '首', '站', '巴西', '就', '掀起', '“', '中国', '旋', '风', '”;', '而', '中国', '深', '耕', '拉', '美的', '大', '背景', '是', ',', '步', '入', '经济', '新', '常态', '的中国', '与', '致力于', '转型', '的', '拉', '美', '正', '调整', '好', '步', '调', '深化', '合作', ',', '新的', '契', '合', '点', '则', '提供了', '新', '动力', '▁', '访问', '中', ',', '李克强', '提出', '中', '拉', '产能', '合作', '新', '模式', ':', '契', '合', '拉', '美国', '家', '需求', ',', '共同', '建设', '物流', '、', '电力', '、', '信息', '三大', '通道', ',', '实现', '南', '美', '大陆', '互', '联', '互', '通', ';', '遵循', '市场', '经济', '规律', ',', '实现', '企业', '、', '社会', '、', '政府', '三', '者', '良', '性', '互动', '的合作', '方式', ';', '围绕', '中', '拉', '合作', '项目', ',', '拓展', '基金', '、', '信贷', '、', '保险', '三', '条', '融资', '渠道', '▁', '中方', '将', '设立', '中', '拉', '产能', '合作', '专项', '基金', ',', '提供', '300', '亿美元', '融资', ',', '支持', '中', '拉', '在', '产能', '和', '装备', '制造', '领域的', '项目', '合作', '▁此外', ',', '中国', '愿', '同', '拉', '美国', '家', '扩大', '货币', '互', '换', '及', '本', '币', '结算', '▁', '对', '拉', '美', '而言', ',', '过去', '10', '年', '大', '宗', '商品', '驱动', '的', '高速', '增长', '带来', '消费', '市场', '繁荣', ',', '但也', '掩', '盖', '了', '结构', '性', '问题', '▁', '教育', '、', '固定', '资产', '、', '基础设施', '投入', '滞', '后', ',', '令', '经济增长', '内', '生', '动力', '不足', '▁', '数据显示', ',', '过去', '几年', '拉', '美', '地区', '投资', '率', '仅', '约', '20%', ',', '远', '低于', '世界', '平均', '水', '准', '▁', '重', '消费', '、', '轻', '投资', '的', '增长', '模式', ',', '制约', '了', '拉', '美', '经济', '可持续', '增长', '▁“', '越来越多', '的声音', '认为', ',', '在', '中', '拉', '日益', '增长', '的', '贸易', '中', ',', '应当', '减少', '对中国', '购买', '拉', '美', '原材料', '的', '关注', ',', '转', '而', '更多', '地', '推动', '中国', '从', '拉', '美', '进口', '加工', '产品', '和', '在', '拉', '美', '增加', '投资', ',', '”', '埃', '菲', '社', '如此', '点', '评', '中', '拉', '经贸', '合作', '新', '趋势', '▁', '分析', '人士', '表示', ',', '中', '拉', '经贸', '合作', '正', '经历', '转变', ':', '由', '劳动', '密集', '型', '产品', '转向', '高端', '制造', '产品', '以及', '服务', '和', '技术', '输出', ',', '从', '以', '贸易', '为主', '转向', '以', '投资', '、', '工程', '承包', '为主', '▁', '而在', 'ꊮ', '基础设施', '、', '信息', '通信', '、', '新能源', '等', '重点', '合作', '领域', ',', '金融', '将', '扮演', '“', '催', '化', '剂', '”', '和', '“', '倍', '增', '器', '”', '的角色', '▁', '中', '巴', '工商', '峰会', '期间', ',', '交通', '银行', '就', '收购', '巴西', 'BB', 'M', '银行', '与', '其', '控股', '股东', '签署', '协议', '▁', '交', '行', '董事长', '牛', '锡', '明', '表示', ',', '交', '行', '将', '为', 'BB', 'M', '银行', '注入', '中国', '元素', ',', '更好', '服务', '两国', '投资', '与', '贸易', '活动', ',', '为', '“', '走出去', '”', '的中', '企', '和', '巴西', '本地', '客户', '提供', '更', '优质的', '金融', '服务', '▁', '国家', '开发', '银行', '与', '巴西', '石油', '公司', '签署', '中', '长期', '融资', '合作', '协议', ',', '并', '与', '巴西', '一', '州', '政府', '及', '国内', '一家', '企业', '就', '玉米', '和', '大', '豆', '深', '加工', '项目', '签署', '合作', '框架', '协议', ',', '共', '涉及', '融资', '金额', '约', '60', '亿美元', '▁此外', ',', '中国', '进出口', '银行', '分别', '与', '巴西', '多家', '机构', '签署', '总', '值', '6', '6.5', '亿美元', '协议', ',', '涉及', '高端', '船', '型', '、', '海洋', '工程', '装备', '、', '航空', '器', '等领域', '▁中国', '出口', '信用', '保险公司', '与', '巴西', '征', '信', '机构', 'SER', 'ASA', '签署', '战略', '合作', '协议', ',', '两', '家', '机构', '将在', '资', '信', '信息', '和', '保', '后', '支持', '服务', '方面', '展开', '长期', '合作', '▁', '据悉', ',', '中国', '信', '保', '在', '巴西', '市场', '累计', '保', '额', '已', '达', '30', '8', '亿美元', ',', '以', '中', '长期', '出口', '信用', '保险', '、', '投资', '保险', '等方式', '支持', '中', '企', '参与', '巴西', '冶', '金', '、', '水泥', '、', '电信', '等', '行业', '14', '个', '长期', '项目', ',', '未来', '将继续', '支持', '产能', '、', '农业', '和', '本', '币', '互', '换', '等领域', '合作', '▁', '此前', ',', '中国', '央行', '分别', '与', '阿根廷', '和', '巴西', '央行', '签署', '双边', '本', '币', '互', '换', '协议', '▁', '据悉', ',', '智', '利', '央行', '和', '中国', '央行', '有关', '本', '币', '互', '换', '的', '谈判', '也', '取得', '进展', '▁', '通过', '货币', '互', '换', ',', '可', '相互', '提供', '短期', '流动', '性', '支持', ',', '并', '为', '本', '国', '商业', '银行', '在', '对方', '国家', '分', '支', '机构', '提供', '该', '国', '货币', '的', '融资', '便利', ',', '帮助', '企业', '规', '避', '汇率', '风险', '和', '降低', '交易', '成本', '▁而', '本', '币', '结算', '有助于', '汇率', '形成', '机制', ',', '贸易', '和', '投', '融资', '将', '得到', '跃', '升', '▁中国', '资本', '“', '走出去', '”', '带动', '中', '企', '和', '高端', '装备', '“', '出', '海', '”,', '拉', '美', '成为', '最具', '潜力', '市场', '之一', '▁目前', ',', '中国', '与', '阿根廷', '、', '巴西', '在', '动', '车', '生产', '领域', '深度', '对', '接', '▁', '截至', '2014', '年', '年底', ',', '中国', '累计', '在', '拉', '美', '和', '加', '勒', '比', '国家', '新', '签', '工程', '承包', '额', '超过', '1', '100', '亿美元', ',', '涉及', '天然气', '、', '管道', '、', '电', '站', '、', '公路', '、', '港口', '、', '住房', '、', '通信', '和', '铁路', '等领域', '▁', '拉', '美', '开发', '银行', '行', '长', '加', '西', '亚', '表示', ',', '拉', '美', '基础设施', '相对', '薄', '弱', '、', '工业', '化', '水', '准', '较低', ',', '而', '中国', '在', '技术', '、', '资金', '和', '经验', '方面', '有', '优势', ',', '双方', '进行', '产能', '合作', '“', '恰', '逢', '其', '时', '”', '▁', '拉', '美', '开发', '银行', '将', '积极', '融入', '双方', '金融', '合作', ',', '为', '中', '企', '进', '军', '拉', '美', '和', '加速', '国际', '融合', '铺', '平', '道路', '▁随着', '巴西', '成为', '亚', '投', '行', '在', '美洲', '的', '唯一', '意向', '创', '始', '成员国', ',', '审', '视', '中', '拉', '金融', '合作的', '视野', '更为', '宽', '广', '▁“', '巴西', '有不少', '国际', '项目', '经验', '丰富的', '建筑', '承包', '企业', ',', '在', '亚洲', '也有', '业务', ',', '亚', '投', '行的', '创立', '客观', '上', '有助于', '拉', '近', '巴西', '与', '整个', '亚洲', '的', '距离', ',', '”', '巴西', '驻', '华', '大使', '雷', '昂', '说', '▁', '智', '利', '总统', '巴', '切', '莱', '特', '也', '表示', ',', '亚', '投', '行', '很重要', ',', '智', '利', '正在', '评估', '加入', '亚', '投', '行的', '可行性', '▁从', '初', '级', '产品', '贸易', '到', '发展战略', '对', '接', ',', '中', '拉', '深度', '融合', '开', '辟', '了', '广', '阔', '的合作', '前景', ',', '也将', '助', '推', '世界', '经济', '均衡', '、', '可持续', '增长', '▁(', '完', ')']\n",
      "Token IDs:  [15, 6717, 1612, 1930, 40338, 16, 514, 3300, 170399, 5693, 121784, 10784, 1107, 14264, 1420, 1971, 7961, 8976, 13849, 36341, 235992, 6, 104352, 8732, 758, 630, 3117, 55079, 514, 3300, 170399, 5693, 121784, 10784, 1107, 14264, 1420, 1971, 7961, 8976, 13849, 36341, 235992, 6, 104352, 11410, 19828, 13338, 7688, 169351, 1549, 635, 4, 79480, 30690, 10609, 112201, 96966, 19402, 30845, 85956, 7961, 11560, 79480, 56280, 84072, 51806, 86017, 217862, 6, 217862, 86017, 48533, 30690, 10609, 112201, 155, 1930, 12821, 63, 3715, 218310, 3182, 7985, 187842, 42139, 12, 1965, 22620, 37, 14085, 789, 11537, 66088, 4, 514, 3300, 170399, 5693, 174561, 4465, 23368, 4, 3302, 83554, 1040, 1378, 9420, 12550, 6, 17025, 72750, 1433, 12617, 4, 23032, 6806, 264, 246293, 22878, 8522, 4, 3933, 217862, 3300, 2655, 2003, 213, 6342, 5370, 79480, 887, 192918, 155, 1930, 84325, 7149, 53956, 1107, 1930, 6728, 94801, 3300, 55814, 573, 35073, 354, 4, 13355, 2283, 5411, 1378, 207253, 84072, 1189, 86431, 97523, 43, 3300, 2655, 3302, 28933, 1322, 13355, 17619, 82531, 5693, 4, 12122, 82922, 3985, 2391, 14349, 39579, 1378, 50378, 6, 56280, 514, 4, 217862, 12092, 514, 3300, 158366, 5693, 1378, 12250, 12, 82922, 3985, 3300, 3893, 1433, 10637, 4, 9612, 5722, 41049, 37, 116824, 37, 5412, 73352, 99348, 4, 10725, 4617, 2655, 64940, 30588, 16356, 30588, 3909, 74, 148556, 4362, 5411, 121537, 4, 10725, 2997, 37, 4491, 37, 4016, 1971, 1548, 21404, 1278, 95444, 98024, 6518, 74, 85811, 514, 3300, 5693, 6806, 4, 73837, 20710, 37, 193891, 37, 33831, 1971, 7781, 66088, 57696, 6, 107655, 1726, 76631, 514, 3300, 158366, 5693, 94958, 20710, 4, 2212, 7739, 41781, 66088, 4, 7499, 514, 3300, 213, 158366, 264, 94638, 28181, 82321, 6806, 5693, 74000, 4, 1930, 38468, 3169, 3300, 3893, 1433, 45868, 72652, 30588, 19543, 1102, 1516, 90874, 224591, 6, 1036, 3300, 2655, 27283, 4, 26224, 963, 470, 573, 30751, 6689, 129239, 43, 50500, 15346, 25638, 26032, 4362, 155470, 4, 99559, 106036, 59813, 274, 30530, 1278, 4258, 6, 3372, 37, 41284, 32310, 37, 91339, 23584, 113737, 1826, 4, 12668, 147815, 3182, 2026, 50378, 23737, 6, 93940, 4, 26224, 63839, 3300, 2655, 12965, 8522, 5133, 31723, 10609, 51271, 4, 14062, 93301, 3221, 21596, 1553, 27883, 6, 2830, 26032, 37, 39687, 8522, 43, 15346, 12250, 4, 208579, 274, 3300, 2655, 5411, 192193, 15346, 52, 99231, 85026, 9413, 4, 213, 514, 3300, 73663, 15346, 43, 22620, 514, 4, 36260, 36325, 112680, 29145, 3300, 2655, 206262, 43, 17900, 4, 11359, 1107, 8107, 955, 19608, 1930, 1965, 3300, 2655, 58078, 35671, 5889, 264, 213, 3300, 2655, 10161, 8522, 4, 63, 50306, 36483, 6808, 13296, 2391, 32219, 514, 3300, 170399, 5693, 1378, 64577, 6, 7949, 18290, 2575, 4, 514, 3300, 170399, 5693, 3302, 42429, 97973, 12, 2719, 46864, 159309, 4622, 5889, 203239, 93514, 28181, 5889, 2961, 3367, 264, 5052, 188302, 4, 1965, 1034, 22620, 80539, 203239, 1034, 8522, 37, 8393, 177011, 80539, 6, 59345, 3, 91339, 37, 5412, 41011, 37, 150601, 844, 22613, 5693, 17010, 4, 8976, 1726, 89349, 155, 72287, 1988, 62249, 63, 264, 155, 16267, 19426, 5032, 63, 95479, 6, 514, 7521, 64489, 139731, 24055, 4, 10766, 14565, 887, 107171, 79480, 22312, 594, 14565, 1189, 2413, 134374, 106341, 107870, 33704, 6, 6582, 2003, 117377, 13983, 156451, 3924, 2575, 4, 6582, 2003, 1726, 1064, 22312, 594, 14565, 156534, 1930, 54322, 4, 54742, 3367, 71355, 8522, 1189, 22620, 7005, 4, 1064, 155, 204943, 63, 79213, 31437, 264, 79480, 65992, 13618, 2212, 1955, 154096, 8976, 3367, 6, 3744, 15160, 14565, 1189, 79480, 60215, 1903, 107870, 514, 27065, 66088, 5693, 33704, 4, 2672, 1189, 79480, 684, 7800, 4016, 1102, 13853, 18994, 2997, 887, 199647, 264, 573, 24109, 6728, 35671, 6806, 107870, 5693, 106638, 33704, 4, 6233, 42263, 66088, 102584, 10609, 4598, 41781, 74000, 4, 1930, 225022, 14565, 41436, 1189, 79480, 79515, 11818, 107870, 7051, 10502, 910, 136473, 41781, 33704, 4, 42263, 93514, 15065, 4622, 37, 45550, 8393, 94638, 37, 31748, 5032, 173927, 54888, 28100, 46220, 209427, 1189, 79480, 25786, 5070, 11818, 50184, 30106, 107870, 24872, 5693, 33704, 4, 6442, 1433, 11818, 53904, 26288, 5070, 5412, 264, 6082, 1826, 7499, 3367, 7165, 74823, 27065, 5693, 6, 113254, 4, 1930, 5070, 6082, 213, 79480, 4362, 123678, 6082, 22878, 3123, 9186, 1197, 1019, 41781, 4, 1034, 514, 27065, 28100, 46220, 33831, 37, 8522, 33831, 186416, 7499, 514, 31437, 17729, 79480, 192648, 2006, 37, 159622, 37, 145681, 844, 8205, 2592, 3294, 27065, 6806, 4, 12555, 156731, 7499, 158366, 37, 37696, 264, 1516, 90874, 30588, 19543, 173927, 5693, 6, 62978, 4, 1930, 120903, 41436, 1189, 150708, 264, 79480, 120903, 107870, 219279, 1516, 90874, 30588, 19543, 33704, 6, 113254, 4, 15624, 3908, 120903, 264, 1930, 120903, 16570, 1516, 90874, 30588, 19543, 43, 103504, 886, 13809, 111597, 6, 4511, 72652, 30588, 19543, 4, 1403, 41294, 2212, 67755, 107152, 1278, 7499, 4, 2672, 1064, 1516, 3024, 26006, 14565, 213, 41574, 3744, 1583, 11963, 11818, 2212, 4941, 3024, 72652, 43, 66088, 27094, 4, 12658, 2997, 42709, 42597, 182165, 23400, 264, 24925, 11755, 15446, 56584, 1516, 90874, 224591, 139137, 182165, 17351, 38238, 4, 22620, 264, 11537, 66088, 1726, 10007, 121784, 14264, 54888, 44508, 155, 204943, 63, 140758, 514, 31437, 264, 93514, 94638, 155, 1040, 2767, 633, 3300, 2655, 8315, 121601, 125145, 4362, 9632, 59951, 4, 1930, 1189, 150708, 37, 79480, 213, 7447, 3715, 8550, 17010, 68414, 1036, 5838, 6, 75205, 7360, 470, 60838, 4, 1930, 123678, 213, 3300, 2655, 264, 3490, 25931, 2615, 3744, 1378, 53730, 8393, 177011, 22878, 18292, 418, 3559, 41781, 4, 42263, 196182, 37, 91295, 37, 8312, 5370, 37, 82495, 37, 158649, 37, 56021, 37, 41011, 264, 86753, 173927, 6, 3300, 2655, 15160, 14565, 2003, 3846, 3490, 3891, 10783, 2575, 4, 3300, 2655, 91339, 45945, 27080, 17956, 37, 22065, 1988, 1553, 27883, 180394, 4, 1107, 1930, 213, 5052, 37, 18635, 264, 23978, 7165, 465, 34636, 4, 29657, 3327, 158366, 5693, 155, 108839, 68838, 2413, 1898, 63, 6, 3300, 2655, 15160, 14565, 1726, 14875, 79821, 29657, 8976, 5693, 4, 1064, 514, 31437, 10132, 9002, 3300, 2655, 264, 71698, 5559, 43631, 111688, 5511, 27246, 85732, 79480, 8315, 10783, 11537, 2003, 213, 158956, 43, 36407, 189624, 27638, 44134, 215671, 4, 53654, 18646, 514, 3300, 8976, 123414, 177301, 101516, 41247, 32004, 52, 79480, 111773, 5559, 6806, 23978, 84320, 19958, 177011, 2997, 4, 213, 47483, 13264, 13046, 4, 10783, 11537, 89136, 205154, 141413, 575, 139137, 3300, 4169, 79480, 1189, 20898, 47483, 43, 47348, 4, 63, 79480, 50865, 7919, 96581, 12239, 75039, 1612, 6, 15624, 3908, 36633, 7521, 7847, 40243, 2657, 886, 2575, 4, 10783, 11537, 2003, 92295, 4, 15624, 3908, 11560, 62193, 15104, 10783, 11537, 89136, 243272, 66816, 9224, 10784, 5889, 22620, 789, 184013, 1036, 5838, 4, 514, 3300, 68414, 43631, 4185, 189657, 274, 32004, 103983, 98024, 92288, 4, 119016, 13849, 10238, 3221, 5411, 165636, 37, 192193, 15346, 15, 8943, 16]\n"
     ]
    }
   ],
   "source": [
    "# Print the original sentence.\n",
    "print(' Original: ', sentences[0])\n",
    "\n",
    "# Print the sentence split into tokens.\n",
    "print('Tokenized: ', tokenizer.tokenize(sentences[0]))\n",
    "\n",
    "# Print the sentence mapped to token ids.\n",
    "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentences[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeNIc4auFUdF"
   },
   "source": [
    "When we actually convert all of our sentences, we'll use the `tokenize.encode` function to handle both steps, rather than calling `tokenize` and `convert_tokens_to_ids` separately. \n",
    "\n",
    "Before we can do that, though, we need to talk about some of BERT's formatting requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "viKGCCh8izww"
   },
   "source": [
    "## 3.2. Required Formatting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDcqNlvVhL5W"
   },
   "source": [
    "The above code left out a few required formatting steps that we'll look at here.\n",
    "\n",
    "*Side Note: The input format to BERT seems \"over-specified\" to me... We are required to give it a number of pieces of information which seem redundant, or like they could easily be inferred from the data without us explicity providing it. But it is what it is, and I suspect it will make more sense once I have a deeper understanding of the BERT internals.*\n",
    "\n",
    "We are required to:\n",
    "1. Add special tokens to the start and end of each sentence.\n",
    "2. Pad & truncate all sentences to a single constant length.\n",
    "3. Explicitly differentiate real tokens from padding tokens with the \"attention mask\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6mceWWOjZnw"
   },
   "source": [
    "### Special Tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykk0P9JiKtVe"
   },
   "source": [
    "\n",
    "**`[SEP]`**\n",
    "\n",
    "At the end of every sentence, we need to append the special `[SEP]` token. \n",
    "\n",
    "This token is an artifact of two-sentence tasks, where BERT is given two separate sentences and asked to determine something (e.g., can the answer to the question in sentence A be found in sentence B?). \n",
    "\n",
    "I am not certain yet why the token is still required when we have only single-sentence input, but it is!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86C9objaKu8f"
   },
   "source": [
    "**`[CLS]`**\n",
    "\n",
    "For classification tasks, we must prepend the special `[CLS]` token to the beginning of every sentence.\n",
    "\n",
    "This token has special significance. BERT consists of 12 Transformer layers. Each transformer takes in a list of token embeddings, and produces the same number of embeddings on the output (but with the feature values changed, of course!).\n",
    "\n",
    "![Illustration of CLS token purpose](https://drive.google.com/uc?export=view&id=1ck4mvGkznVJfW3hv6GUqcdGepVTOx7HE)\n",
    "\n",
    "On the output of the final (12th) transformer, *only the first embedding (corresponding to the [CLS] token) is used by the classifier*.\n",
    "\n",
    ">  \"The first token of every sequence is always a special classification token (`[CLS]`). The final hidden state\n",
    "corresponding to this token is used as the aggregate sequence representation for classification\n",
    "tasks.\" (from the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\n",
    "\n",
    "You might think to try some pooling strategy over the final embeddings, but this isn't necessary. Because BERT is trained to only use this [CLS] token for classification, we know that the model has been motivated to encode everything it needs for the classification step into that single 768-value embedding vector. It's already done the pooling for us!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u51v0kFxeteu"
   },
   "source": [
    "### Sentence Length & Attention Mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPNuwqZVK3T6"
   },
   "source": [
    "The sentences in our dataset obviously have varying lengths, so how does BERT handle this?\n",
    "\n",
    "BERT has two constraints:\n",
    "1. All sentences must be padded or truncated to a single, fixed length.\n",
    "2. The maximum sentence length is 512 tokens.\n",
    "\n",
    "Padding is done with a special `[PAD]` token, which is at index 0 in the BERT vocabulary. The below illustration demonstrates padding out to a \"MAX_LEN\" of 8 tokens.\n",
    "\n",
    "<img src=\"https://drive.google.com/uc?export=view&id=1cb5xeqLu_5vPOgs3eRnail2Y00Fl2pCo\" width=\"600\">\n",
    "\n",
    "The \"Attention Mask\" is simply an array of 1s and 0s indicating which tokens are padding and which aren't (seems kind of redundant, doesn't it?!). This mask tells the \"Self-Attention\" mechanism in BERT not to incorporate these PAD tokens into its interpretation of the sentence.\n",
    "\n",
    "The maximum length does impact training and evaluation speed, however. \n",
    "For example, with a Tesla K80:\n",
    "\n",
    "`MAX_LEN = 128  -->  Training epochs take ~5:28 each`\n",
    "\n",
    "`MAX_LEN = 64   -->  Training epochs take ~2:57 each`\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6w8elb-58GJ"
   },
   "source": [
    "## 3.3. Tokenize Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U28qy4P-NwQ9"
   },
   "source": [
    "The transformers library provides a helpful `encode` function which will handle most of the parsing and data prep steps for us.\n",
    "\n",
    "Before we are ready to encode our text, though, we need to decide on a **maximum sentence length** for padding / truncating to.\n",
    "\n",
    "The below cell will perform one tokenization pass of the dataset in order to measure the maximum sentence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cKsH2sU0OCQA",
    "outputId": "941f2c26-f7b3-4527-b5bc-e05b32a4b39d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  18123\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "\n",
    "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
    "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
    "\n",
    "    # Update the maximum sentence length.\n",
    "    max_len = max(max_len, len(input_ids))\n",
    "\n",
    "print('Max sentence length: ', max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1M296yz577fV"
   },
   "source": [
    "Just in case there are some longer test sentences, I'll set the maximum length to 64.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tIWAoWL2RK1p"
   },
   "source": [
    "Now we're ready to perform the real tokenization.\n",
    "\n",
    "The `tokenizer.encode_plus` function combines multiple steps for us:\n",
    "\n",
    "1. Split the sentence into tokens.\n",
    "2. Add the special `[CLS]` and `[SEP]` tokens.\n",
    "3. Map the tokens to their IDs.\n",
    "4. Pad or truncate all sentences to the same length.\n",
    "5. Create the attention masks which explicitly differentiate real tokens from `[PAD]` tokens.\n",
    "\n",
    "The first four features are in `tokenizer.encode`, but I'm using `tokenizer.encode_plus` to get the fifth item (attention masks). Documentation is [here](https://huggingface.co/transformers/main_classes/tokenizer.html?highlight=encode_plus#transformers.PreTrainedTokenizer.encode_plus).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2bBdb3pt8LuQ",
    "outputId": "61e83562-e824-4d09-ccd2-6a13a2a0cc51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/share/pkg.7/transformers/4.5.0/install/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2073: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:  （世说中国策）中拉经贸合作跃级而升之三——金融助益转型升级\n",
      "新华社北京５月２１日电中拉经贸合作跃级而升之三——金融助益转型升级\n",
      "新华社记者刘云非当地时间２０日，巴西裏约地铁迎来一位特殊乘客——正在巴西访问的中国国务院总理李克强\n",
      "李克强总理坐在裏约地铁“中国造”车厢内具有象徵意义：从贸易、产业到投融资，中拉经贸合作渐次推进，正呈现出新图景\n",
      "\n",
      "海外观察家指出，大型项目和钜额投资，让李克强拉美行在首站巴西就掀起“中国旋风”；而中国深耕拉美的大背景是，步入经济新常态的中国与致力于转型的拉美正调整好步调深化合作，新的契合点则提供了新动力\n",
      "\n",
      "访问中，李克强提出中拉产能合作新模式：契合拉美国家需求，共同建设物流、电力、信息三大通道，实现南美大陆互联互通；遵循市场经济规律，实现企业、社会、政府三者良性互动的合作方式；围绕中拉合作项目，拓展基金、信贷、保险三条融资渠道\n",
      "中方将设立中拉产能合作专项基金，提供３００亿美元融资，支持中拉在产能和装备制造领域的项目合作\n",
      "此外，中国愿同拉美国家扩大货币互换及本币结算\n",
      "\n",
      "对拉美而言，过去１０年大宗商品驱动的高速增长带来消费市场繁荣，但也掩盖了结构性问题\n",
      "教育、固定资产、基础设施投入滞后，令经济增长内生动力不足\n",
      "数据显示，过去几年拉美地区投资率仅约２０％，远低于世界平均水准\n",
      "重消费、轻投资的增长模式，制约了拉美经济可持续增长\n",
      "\n",
      "“越来越多的声音认为，在中拉日益增长的贸易中，应当减少对中国购买拉美原材料的关注，转而更多地推动中国从拉美进口加工产品和在拉美增加投资，”埃菲社如此点评中拉经贸合作新趋势\n",
      "\n",
      "分析人士表示，中拉经贸合作正经历转变：由劳动密集型产品转向高端制造产品以及服务和技术输出，从以贸易为主转向以投资、工程承包为主\n",
      "而在ꊮ基础设施、信息通信、新能源等重点合作领域，金融将扮演“催化剂”和“倍增器”的角色\n",
      "\n",
      "中巴工商峰会期间，交通银行就收购巴西ＢＢＭ银行与其控股股东签署协议\n",
      "交行董事长牛锡明表示，交行将为ＢＢＭ银行注入中国元素，更好服务两国投资与贸易活动，为“走出去”的中企和巴西本地客户提供更优质的金融服务\n",
      "\n",
      "国家开发银行与巴西石油公司签署中长期融资合作协议，并与巴西一州政府及国内一家企业就玉米和大豆深加工项目签署合作框架协议，共涉及融资金额约６０亿美元\n",
      "此外，中国进出口银行分别与巴西多家机构签署总值６６．５亿美元协议，涉及高端船型、海洋工程装备、航空器等领域\n",
      "\n",
      "中国出口信用保险公司与巴西征信机构ＳＥＲＡＳＡ签署战略合作协议，两家机构将在资信信息和保后支持服务方面展开长期合作\n",
      "据悉，中国信保在巴西市场累计保额已达３０８亿美元，以中长期出口信用保险、投资保险等方式支持中企参与巴西冶金、水泥、电信等行业１４个长期项目，未来将继续支持产能、农业和本币互换等领域合作\n",
      "\n",
      "此前，中国央行分别与阿根廷和巴西央行签署双边本币互换协议\n",
      "据悉，智利央行和中国央行有关本币互换的谈判也取得进展\n",
      "通过货币互换，可相互提供短期流动性支持，并为本国商业银行在对方国家分支机构提供该国货币的融资便利，帮助企业规避汇率风险和降低交易成本\n",
      "而本币结算有助于汇率形成机制，贸易和投融资将得到跃升\n",
      "\n",
      "中国资本“走出去”带动中企和高端装备“出海”，拉美成为最具潜力市场之一\n",
      "目前，中国与阿根廷、巴西在动车生产领域深度对接\n",
      "截至２０１４年年底，中国累计在拉美和加勒比国家新签工程承包额超过１１００亿美元，涉及天然气、管道、电站、公路、港口、住房、通信和铁路等领域\n",
      "\n",
      "拉美开发银行行长加西亚表示，拉美基础设施相对薄弱、工业化水准较低，而中国在技术、资金和经验方面有优势，双方进行产能合作“恰逢其时”\n",
      "拉美开发银行将积极融入双方金融合作，为中企进军拉美和加速国际融合铺平道路\n",
      "\n",
      "随着巴西成为亚投行在美洲的唯一意向创始成员国，审视中拉金融合作的视野更为宽广\n",
      "“巴西有不少国际项目经验丰富的建筑承包企业，在亚洲也有业务，亚投行的创立客观上有助于拉近巴西与整个亚洲的距离，”巴西驻华大使雷昂说\n",
      "智利总统巴切莱特也表示，亚投行很重要，智利正在评估加入亚投行的可行性\n",
      "\n",
      "从初级产品贸易到发展战略对接，中拉深度融合开辟了广阔的合作前景，也将助推世界经济均衡、可持续增长\n",
      "（完）\n",
      "Token IDs: tensor([     0,     15,   6717,   1612,   1930,  40338,     16,    514,   3300,\n",
      "        170399,   5693, 121784,  10784,   1107,  14264,   1420,   1971,   7961,\n",
      "          8976,  13849,  36341, 235992,      6, 104352,   8732,    758,    630,\n",
      "          3117,  55079,    514,   3300, 170399,   5693, 121784,  10784,   1107,\n",
      "         14264,   1420,   1971,   7961,   8976,  13849,  36341, 235992,      6,\n",
      "        104352,  11410,  19828,  13338,   7688, 169351,   1549,    635,      4,\n",
      "         79480,  30690,  10609, 112201,  96966,  19402,  30845,  85956,   7961,\n",
      "         11560,  79480,  56280,  84072,  51806,  86017, 217862,      6, 217862,\n",
      "         86017,  48533,  30690,  10609, 112201,    155,   1930,  12821,     63,\n",
      "          3715, 218310,   3182,   7985, 187842,  42139,     12,   1965,  22620,\n",
      "            37,  14085,    789,  11537,  66088,      4,    514,   3300, 170399,\n",
      "          5693, 174561,   4465,  23368,      4,   3302,  83554,   1040,   1378,\n",
      "          9420,  12550,      6,  17025,  72750,   1433,  12617,      4,  23032,\n",
      "          6806,    264, 246293,  22878,   8522,      4,   3933, 217862,   3300,\n",
      "          2655,   2003,    213,   6342,   5370,  79480,    887, 192918,    155,\n",
      "          1930,  84325,   7149,  53956,   1107,   1930,   6728,  94801,   3300,\n",
      "         55814,    573,  35073,    354,      4,  13355,   2283,   5411,   1378,\n",
      "        207253,  84072,   1189,  86431,  97523,     43,   3300,   2655,   3302,\n",
      "         28933,   1322,  13355,  17619,  82531,   5693,      4,  12122,  82922,\n",
      "          3985,   2391,  14349,  39579,   1378,  50378,      6,  56280,    514,\n",
      "             4, 217862,  12092,    514,   3300, 158366,   5693,   1378,  12250,\n",
      "            12,  82922,   3985,   3300,   3893,   1433,  10637,      4,   9612,\n",
      "          5722,  41049,     37, 116824,     37,   5412,  73352,  99348,      4,\n",
      "         10725,   4617,   2655,  64940,  30588,  16356,  30588,   3909,     74,\n",
      "        148556,   4362,   5411, 121537,      4,  10725,   2997,     37,   4491,\n",
      "            37,   4016,   1971,   1548,  21404,   1278,  95444,  98024,   6518,\n",
      "            74,  85811,    514,   3300,   5693,   6806,      4,  73837,  20710,\n",
      "            37, 193891,     37,  33831,   1971,   7781,  66088,  57696,      6,\n",
      "        107655,   1726,  76631,    514,   3300, 158366,   5693,  94958,  20710,\n",
      "             4,   2212,   7739,  41781,  66088,      4,   7499,    514,   3300,\n",
      "           213, 158366,    264,  94638,  28181,  82321,   6806,   5693,  74000,\n",
      "             4,   1930,  38468,   3169,   3300,   3893,   1433,  45868,  72652,\n",
      "         30588,  19543,   1102,   1516,  90874, 224591,      6,   1036,   3300,\n",
      "          2655,  27283,      4,  26224,    963,    470,    573,  30751,   6689,\n",
      "        129239,     43,  50500,  15346,  25638,  26032,   4362, 155470,      4,\n",
      "         99559, 106036,  59813,    274,  30530,   1278,   4258,      6,   3372,\n",
      "            37,  41284,  32310,     37,  91339,  23584, 113737,   1826,      4,\n",
      "         12668, 147815,   3182,   2026,  50378,  23737,      6,  93940,      4,\n",
      "         26224,  63839,   3300,   2655,  12965,   8522,   5133,  31723,  10609,\n",
      "         51271,      4,  14062,  93301,   3221,  21596,   1553,  27883,      6,\n",
      "          2830,  26032,     37,  39687,   8522,     43,  15346,  12250,      4,\n",
      "        208579,    274,   3300,   2655,   5411, 192193,  15346,     52,  99231,\n",
      "         85026,   9413,      4,    213,    514,   3300,  73663,  15346,     43,\n",
      "         22620,    514,      4,  36260,  36325, 112680,  29145,   3300,   2655,\n",
      "        206262,     43,  17900,      4,  11359,   1107,   8107,    955,  19608,\n",
      "          1930,   1965,   3300,   2655,  58078,  35671,   5889,    264,    213,\n",
      "          3300,   2655,  10161,   8522,      4,     63,  50306,  36483,   6808,\n",
      "         13296,   2391,  32219,    514,   3300, 170399,   5693,   1378,  64577,\n",
      "             6,   7949,  18290,   2575,      4,    514,   3300, 170399,   5693,\n",
      "          3302,  42429,  97973,     12,   2719,  46864, 159309,   4622,   5889,\n",
      "        203239,  93514,  28181,   5889,   2961,   3367,    264,   5052, 188302,\n",
      "             4,   1965,   1034,  22620,  80539, 203239,   1034,   8522,     37,\n",
      "          8393, 177011,  80539,      6,  59345,      3,  91339,     37,   5412,\n",
      "         41011,     37, 150601,    844,  22613,   5693,  17010,      4,   8976,\n",
      "          1726,  89349,    155,  72287,   1988,  62249,     63,    264,    155,\n",
      "         16267,  19426,   5032,     63,  95479,      6,    514,   7521,  64489,\n",
      "        139731,  24055,      4,  10766,  14565,    887, 107171,      2])\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# For every sentence...\n",
    "for sent in sentences:\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 512,           # Pad & truncate all sentences.\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "    \n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    \n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(labels)\n",
    "\n",
    "# Print sentence 0, now as a list of IDs.\n",
    "print('Original: ', sentences[0])\n",
    "print('Token IDs:', input_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aRp4O7D295d_"
   },
   "source": [
    "## 3.4. Training & Validation Split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qu0ao7p8rb06"
   },
   "source": [
    "Divide up our training set to use 90% for training and 10% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GEgLpFVlo1Z-",
    "outputId": "924f8893-c43a-41e9-e939-b6e0cda953e4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 90-10 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.9 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_idx, valid_idx = train_test_split(np.arange(len(labels)), test_size=0.1, shuffle=True, stratify=labels,random_state=10)\n",
    "\n",
    "train_idx = np.concatenate([train_idx, valid_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dD9i6Z2pG-sN"
   },
   "source": [
    "We'll also create an iterator for our dataset using the torch DataLoader class. This helps save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "XGUqOCtgqGhP"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# The DataLoader needs to know our batch size for training, so we specify it \n",
    "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
    "# size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "train_sampler = torch.utils.data.SubsetRandomSampler(train_idx)\n",
    "train_dataloader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8bwa6Rts-02-"
   },
   "source": [
    "# 4. Train Our Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3xYQ3iLO08SX"
   },
   "source": [
    "Now that our input data is properly formatted, it's time to fine tune the BERT model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D6TKgyUzPIQc"
   },
   "source": [
    "## 4.1. BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sjzRT1V0zwm"
   },
   "source": [
    "For this task, we first want to modify the pre-trained BERT model to give outputs for classification, and then we want to continue training the model on our dataset until that the entire model, end-to-end, is well-suited for our task. \n",
    "\n",
    "Thankfully, the huggingface pytorch implementation includes a set of interfaces designed for a variety of NLP tasks. Though these interfaces are all built on top of a trained BERT model, each has different top layers and output types designed to accomodate their specific NLP task.  \n",
    "\n",
    "Here is the current list of classes provided for fine-tuning:\n",
    "* BertModel\n",
    "* BertForPreTraining\n",
    "* BertForMaskedLM\n",
    "* BertForNextSentencePrediction\n",
    "* **BertForSequenceClassification** - The one we'll use.\n",
    "* BertForTokenClassification\n",
    "* BertForQuestionAnswering\n",
    "\n",
    "The documentation for these can be found under [here](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXYitPoE-cjH"
   },
   "source": [
    "\n",
    "\n",
    "We'll be using [BertForSequenceClassification](https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#bertforsequenceclassification). This is the normal BERT model with an added single linear layer on top for classification that we will use as a sentence classifier. As we feed input data, the entire pre-trained BERT model and the additional untrained classification layer is trained on our specific task. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WnQW9E-bBCRt"
   },
   "source": [
    "OK, let's load BERT! There are a few different pre-trained BERT models available. \"bert-base-uncased\" means the version that has only lowercase letters (\"uncased\") and is the smaller version of the two (\"base\" vs \"large\").\n",
    "\n",
    "The documentation for `from_pretrained` can be found [here](https://huggingface.co/transformers/v2.2.0/main_classes/model.html#transformers.PreTrainedModel.from_pretrained), with the additional parameters defined [here](https://huggingface.co/transformers/v2.2.0/main_classes/configuration.html#transformers.PretrainedConfig)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gFsCTp_mporB",
    "outputId": "dea49eb9-65f7-4a7a-ba27-d8be35f2fcda"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import XLMRobertaForSequenceClassification, AdamW, XLMRobertaConfig\n",
    "\n",
    "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
    "# linear classification layer on top. \n",
    "model = XLMRobertaForSequenceClassification.from_pretrained(\n",
    "    \"xlm-roberta-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
    "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
    "                    # You can increase this for multi-class tasks.   \n",
    "    output_attentions = False, # Whether the model returns attentions weights.\n",
    "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
    ")\n",
    "\n",
    "# Tell pytorch to run this model on the GPU.\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0Jv6c7-HHDW"
   },
   "source": [
    "Just for curiosity's sake, we can browse all of the model's parameters by name here.\n",
    "\n",
    "In the below cell, I've printed out the names and dimensions of the weights for:\n",
    "\n",
    "1. The embedding layer.\n",
    "2. The first of the twelve transformers.\n",
    "3. The output layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8PIiVlDYCtSq",
    "outputId": "451dbac8-7022-48cd-d9af-deeb97a2984a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 201 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "roberta.embeddings.word_embeddings.weight               (250002, 768)\n",
      "roberta.embeddings.position_embeddings.weight             (514, 768)\n",
      "roberta.embeddings.token_type_embeddings.weight             (1, 768)\n",
      "roberta.embeddings.LayerNorm.weight                           (768,)\n",
      "roberta.embeddings.LayerNorm.bias                             (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "roberta.encoder.layer.0.attention.self.query.weight       (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.query.bias             (768,)\n",
      "roberta.encoder.layer.0.attention.self.key.weight         (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.key.bias               (768,)\n",
      "roberta.encoder.layer.0.attention.self.value.weight       (768, 768)\n",
      "roberta.encoder.layer.0.attention.self.value.bias             (768,)\n",
      "roberta.encoder.layer.0.attention.output.dense.weight     (768, 768)\n",
      "roberta.encoder.layer.0.attention.output.dense.bias           (768,)\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.weight       (768,)\n",
      "roberta.encoder.layer.0.attention.output.LayerNorm.bias       (768,)\n",
      "roberta.encoder.layer.0.intermediate.dense.weight        (3072, 768)\n",
      "roberta.encoder.layer.0.intermediate.dense.bias              (3072,)\n",
      "roberta.encoder.layer.0.output.dense.weight              (768, 3072)\n",
      "roberta.encoder.layer.0.output.dense.bias                     (768,)\n",
      "roberta.encoder.layer.0.output.LayerNorm.weight               (768,)\n",
      "roberta.encoder.layer.0.output.LayerNorm.bias                 (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "classifier.dense.weight                                   (768, 768)\n",
      "classifier.dense.bias                                         (768,)\n",
      "classifier.out_proj.weight                                  (2, 768)\n",
      "classifier.out_proj.bias                                        (2,)\n"
     ]
    }
   ],
   "source": [
    "# Get all of the model's parameters as a list of tuples.\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qRWT-D4U_Pvx"
   },
   "source": [
    "## 4.2. Optimizer & Learning Rate Scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8o-VEBobKwHk"
   },
   "source": [
    "Now that we have our model loaded we need to grab the training hyperparameters from within the stored model.\n",
    "\n",
    "For the purposes of fine-tuning, the authors recommend choosing from the following values (from Appendix A.3 of the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf)):\n",
    "\n",
    ">- **Batch size:** 16, 32  \n",
    "- **Learning rate (Adam):** 5e-5, 3e-5, 2e-5  \n",
    "- **Number of epochs:** 2, 3, 4 \n",
    "\n",
    "We chose:\n",
    "* Batch size: 32 (set when creating our DataLoaders)\n",
    "* Learning rate: 2e-5\n",
    "* Epochs: 4 (we'll see that this is probably too many...)\n",
    "\n",
    "The epsilon parameter `eps = 1e-8` is \"a very small number to prevent any division by zero in the implementation\" (from [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)).\n",
    "\n",
    "You can find the creation of the AdamW optimizer in `run_glue.py` [here](https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L109)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GLs72DuMODJO"
   },
   "outputs": [],
   "source": [
    "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
    "# I believe the 'W' stands for 'Weight Decay fix\"\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "-p0upAhhRiIx"
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
    "# training data.\n",
    "epochs = 3\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqfmWwUR_Sox"
   },
   "source": [
    "## 4.3. Training Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QXZhFb4LnV5"
   },
   "source": [
    "Below is our training loop. There's a lot going on, but fundamentally for each pass in our loop we have a trianing phase and a validation phase. \n",
    "\n",
    "> *Thank you to [Stas Bekman](https://ca.linkedin.com/in/stasbekman) for contributing the insights and code for using validation loss to detect over-fitting!*\n",
    "\n",
    "**Training:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Clear out the gradients calculated in the previous pass. \n",
    "    - In pytorch the gradients accumulate by default (useful for things like RNNs) unless you explicitly clear them out.\n",
    "- Forward pass (feed input data through the network)\n",
    "- Backward pass (backpropagation)\n",
    "- Tell the network to update parameters with optimizer.step()\n",
    "- Track variables for monitoring progress\n",
    "\n",
    "**Evalution:**\n",
    "- Unpack our data inputs and labels\n",
    "- Load data onto the GPU for acceleration\n",
    "- Forward pass (feed input data through the network)\n",
    "- Compute loss on our validation data and track variables for monitoring progress\n",
    "\n",
    "Pytorch hides all of the detailed calculations from us, but we've commented the code to point out which of the above steps are happening on each line. \n",
    "\n",
    "> *PyTorch also has some [beginner tutorials](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html#sphx-glr-beginner-blitz-cifar10-tutorial-py) which you may also find helpful.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pE5B99H5H2-W"
   },
   "source": [
    "Define a helper function for calculating accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "9cQNvaZ9bnyy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNhRtWPXH9C3"
   },
   "source": [
    "Helper function for formatting elapsed times as `hh:mm:ss`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gpt6tR83keZD"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cfNIhN19te3N"
   },
   "source": [
    "We're ready to kick off the training!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6J-FYdx6nFE_",
    "outputId": "ff155031-6854-4db5-f497-414c172d1d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    439.    Elapsed: 0:00:12.\n",
      "  Batch    80  of    439.    Elapsed: 0:00:24.\n",
      "  Batch   120  of    439.    Elapsed: 0:00:36.\n",
      "  Batch   160  of    439.    Elapsed: 0:00:47.\n",
      "  Batch   200  of    439.    Elapsed: 0:00:59.\n",
      "  Batch   240  of    439.    Elapsed: 0:01:11.\n",
      "  Batch   280  of    439.    Elapsed: 0:01:23.\n",
      "  Batch   320  of    439.    Elapsed: 0:01:35.\n",
      "  Batch   360  of    439.    Elapsed: 0:01:47.\n",
      "  Batch   400  of    439.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss: 0.48\n",
      "  Training epcoh took: 0:02:10\n",
      "\n",
      "======== Epoch 2 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    439.    Elapsed: 0:00:12.\n",
      "  Batch    80  of    439.    Elapsed: 0:00:24.\n",
      "  Batch   120  of    439.    Elapsed: 0:00:36.\n",
      "  Batch   160  of    439.    Elapsed: 0:00:47.\n",
      "  Batch   200  of    439.    Elapsed: 0:00:59.\n",
      "  Batch   240  of    439.    Elapsed: 0:01:11.\n",
      "  Batch   280  of    439.    Elapsed: 0:01:23.\n",
      "  Batch   320  of    439.    Elapsed: 0:01:35.\n",
      "  Batch   360  of    439.    Elapsed: 0:01:47.\n",
      "  Batch   400  of    439.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss: 0.36\n",
      "  Training epcoh took: 0:02:10\n",
      "\n",
      "======== Epoch 3 / 3 ========\n",
      "Training...\n",
      "  Batch    40  of    439.    Elapsed: 0:00:12.\n",
      "  Batch    80  of    439.    Elapsed: 0:00:24.\n",
      "  Batch   120  of    439.    Elapsed: 0:00:36.\n",
      "  Batch   160  of    439.    Elapsed: 0:00:47.\n",
      "  Batch   200  of    439.    Elapsed: 0:00:59.\n",
      "  Batch   240  of    439.    Elapsed: 0:01:11.\n",
      "  Batch   280  of    439.    Elapsed: 0:01:23.\n",
      "  Batch   320  of    439.    Elapsed: 0:01:35.\n",
      "  Batch   360  of    439.    Elapsed: 0:01:47.\n",
      "  Batch   400  of    439.    Elapsed: 0:01:58.\n",
      "\n",
      "  Average training loss: 0.28\n",
      "  Training epcoh took: 0:02:10\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:06:30 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 38\n",
    "best_accuracy = 0\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "\n",
    "    # Put the model into training mode. Don't be mislead--the call to \n",
    "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
    "    # `dropout` and `batchnorm` layers behave differently during training\n",
    "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        # Unpack this training batch from our dataloader. \n",
    "        #\n",
    "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
    "        # `to` method.\n",
    "        #\n",
    "        # `batch` contains three pytorch tensors:\n",
    "        #   [0]: input ids \n",
    "        #   [1]: attention masks\n",
    "        #   [2]: labels \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    "        # Always clear any previously calculated gradients before performing a\n",
    "        # backward pass. PyTorch doesn't do this automatically because \n",
    "        # accumulating the gradients is \"convenient while training RNNs\". \n",
    "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
    "        model.zero_grad()        \n",
    "\n",
    "        # Perform a forward pass (evaluate the model on this training batch).\n",
    "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
    "        # function and pass down the arguments. The `forward` function is \n",
    "        # documented here: \n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
    "        # The results are returned in a results object, documented here:\n",
    "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
    "        # Specifically, we'll get the loss (because we provided labels) and the\n",
    "        # \"logits\"--the model outputs prior to activation.\n",
    "        result = model(b_input_ids, \n",
    "                       token_type_ids=None, \n",
    "                       attention_mask=b_input_mask, \n",
    "                       labels=b_labels,\n",
    "                       return_dict=True)\n",
    "\n",
    "        loss = result.loss\n",
    "        logits = result.logits\n",
    "\n",
    "        # Accumulate the training loss over all of the batches so that we can\n",
    "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
    "        # single value; the `.item()` function just returns the Python value \n",
    "        # from the tensor.\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "        # Clip the norm of the gradients to 1.0.\n",
    "        # This is to help prevent the \"exploding gradients\" problem.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # Update parameters and take a step using the computed gradient.\n",
    "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
    "        # modified based on their gradients, the learning rate, etc.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Training Time': training_time,\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3rIMRpFYG2XV"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'FinalChineseRelevance')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Chinese Relevance Analysis Train Test Split",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
